{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb78e4f",
   "metadata": {},
   "source": [
    "# Day 1: Python Essentials + LangChain Basics\n",
    "\n",
    "**Learning Goals:**\n",
    "- Python basics (compared to JavaScript)\n",
    "- First LangChain chain\n",
    "- LangSmith observability setup\n",
    "- Build a simple chatbot\n",
    "\n",
    "**Time:** 2-3 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b81b21",
   "metadata": {},
   "source": [
    "## Part 1: Python Essentials for JS Developers\n",
    "\n",
    "Quick comparison of Python vs JavaScript concepts you already know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e312e630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Rohan, Age: 25\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "# 1. VARIABLES & TYPES\n",
    "# Python uses snake_case (not camelCase)\n",
    "user_name = \"Rohan\"  # No 'const' or 'let', just assign\n",
    "age = 25\n",
    "is_active = True  # Capitalized: True/False (not true/false)\n",
    "\n",
    "print(f\"Name: {user_name}, Age: {age}\")  # f-strings are like template literals\n",
    "\n",
    "# Type hints (optional, but helpful)\n",
    "def greet(name: str) -> str:\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "print(greet(\"World\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51f96ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "[2, 4, 6, 8, 10]\n",
      "[2, 4]\n"
     ]
    }
   ],
   "source": [
    "# 2. LISTS vs ARRAYS\n",
    "# Lists are like JS arrays\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "print(numbers[0])  # Same indexing\n",
    "print(numbers[-1])  # Negative indexing (last item) - Python special!\n",
    "\n",
    "# List comprehension (very Pythonic)\n",
    "# JS: const doubled = numbers.map(n => n * 2)\n",
    "doubled = [n * 2 for n in numbers]\n",
    "print(doubled)\n",
    "\n",
    "# Filtering\n",
    "# JS: const evens = numbers.filter(n => n % 2 === 0)\n",
    "evens = [n for n in numbers if n % 2 == 0]\n",
    "print(evens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627d0de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohan\n",
      "not provided\n",
      "name: Rohan\n",
      "age: 25\n",
      "skills: ['JavaScript', 'Node.js', 'AWS']\n"
     ]
    }
   ],
   "source": [
    "# 3. DICTIONARIES vs OBJECTS\n",
    "# Dict is like JS object\n",
    "user = {\n",
    "    \"name\": \"Rohan\",\n",
    "    \"age\": 25,\n",
    "    \"skills\": [\"JavaScript\", \"Node.js\", \"AWS\"]\n",
    "}\n",
    "\n",
    "print(user[\"name\"])  # Use brackets, not dot notation\n",
    "print(user.get(\"email\", \"not provided\"))  # Safe access with default\n",
    "\n",
    "# Looping through dict\n",
    "# JS: for (const [key, value] of Object.entries(user))\n",
    "for key, value in user.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d4761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Hello', 'priority': 'normal'}\n",
      "{'text': 'Urgent!', 'priority': 'high'}\n",
      "user = Rohan\n",
      "action = login\n",
      "status = success\n"
     ]
    }
   ],
   "source": [
    "# 4. FUNCTIONS\n",
    "# Similar to JS, but with some differences\n",
    "\n",
    "# Default parameters\n",
    "def create_message(text: str, priority: str = \"normal\") -> dict:\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"priority\": priority\n",
    "    }\n",
    "\n",
    "print(create_message(\"Hello\"))\n",
    "print(create_message(\"Urgent!\", priority=\"high\"))\n",
    "\n",
    "# **kwargs (like spreading in JS)\n",
    "def log_data(**kwargs):\n",
    "    for key, value in kwargs.items():\n",
    "        print(f\"{key} = {value}\")\n",
    "\n",
    "log_data(user=\"Rohan\", action=\"login\", status=\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9814ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohan (rohan@example.com)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 5. CLASSES (you know this from TypeScript)\n",
    "class User:\n",
    "    def __init__(self, name: str, email: str):  # Constructor\n",
    "        self.name = name  # 'self' is like 'this'\n",
    "        self.email = email\n",
    "        self._token = None  # _ prefix = private by convention\n",
    "    \n",
    "    def get_info(self) -> str:\n",
    "        return f\"{self.name} ({self.email})\"\n",
    "    \n",
    "    def authenticate(self, password: str) -> bool:\n",
    "        # Simplified example\n",
    "        if password == \"secret\":\n",
    "            self._token = \"abc123\"\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "user = User(\"Rohan\", \"rohan@example.com\")\n",
    "print(user.get_info())\n",
    "print(user.authenticate(\"secret\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec33657",
   "metadata": {},
   "source": [
    "## Part 2: Environment Setup\n",
    "\n",
    "Load environment variables and set up our API connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8943670b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenRouter API key loaded\n",
      "‚ÑπÔ∏è  LangSmith tracing disabled (set LANGCHAIN_TRACING_V2=true to enable)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# Check if key exists\n",
    "if not OPENROUTER_API_KEY:\n",
    "    print(\"‚ö†Ô∏è  Please set OPENROUTER_API_KEY in your .env file\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenRouter API key loaded\")\n",
    "\n",
    "# Optional: LangSmith for observability\n",
    "LANGCHAIN_TRACING = os.getenv(\"LANGCHAIN_TRACING_V2\", \"false\") == \"true\"\n",
    "if LANGCHAIN_TRACING:\n",
    "    print(\"‚úÖ LangSmith tracing enabled\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  LangSmith tracing disabled (set LANGCHAIN_TRACING_V2=true to enable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c0dac",
   "metadata": {},
   "source": [
    "## Part 3: Your First LangChain Chain\n",
    "\n",
    "Let's build a simple LLM chain using OpenRouter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef1234e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OPENROUTER_API_KEY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, SystemMessage\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Initialize LLM with OpenRouter\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# OpenRouter uses OpenAI-compatible API\u001b[39;00m\n\u001b[32m      7\u001b[39m llm = ChatOpenAI(\n\u001b[32m      8\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mopenai/gpt-3.5-turbo\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# or any model on OpenRouter\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     openai_api_key=\u001b[43mOPENROUTER_API_KEY\u001b[49m,\n\u001b[32m     10\u001b[39m     openai_api_base=\u001b[33m\"\u001b[39m\u001b[33mhttps://openrouter.ai/api/v1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     temperature=\u001b[32m0.7\u001b[39m,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ LLM initialized with OpenRouter\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'OPENROUTER_API_KEY' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize LLM with OpenRouter\n",
    "# OpenRouter uses OpenAI-compatible API\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-3.5-turbo\",  # or any model on OpenRouter\n",
    "    openai_api_key=OPENROUTER_API_KEY,\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM initialized with OpenRouter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca8321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a blockchain-based platform that aims to provide language learning services using blockchain technology. It leverages the decentralized nature of blockchain to offer secure and transparent language learning solutions. Users can access language courses, connect with tutors, and track their progress through the LangChain platform. The platform also uses smart contracts to facilitate payments and ensure trust between users.\n"
     ]
    }
   ],
   "source": [
    "# Simple direct call (like calling the API directly)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful AI assistant.\"),\n",
    "    HumanMessage(content=\"What is LangChain?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0731237",
   "metadata": {},
   "source": [
    "### Using Prompt Templates\n",
    "\n",
    "Prompt templates help you create reusable prompts with variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190e2e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To read a JSON file in Python, you can use the `json` module which is included in the standard library. Here's a simple example:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "# Open the JSON file in read mode\n",
      "with open('data.json', 'r') as file:\n",
      "    data = json.load(file)\n",
      "\n",
      "# Now you can access the data as a Python dictionary\n",
      "print(data)\n",
      "```\n",
      "\n",
      "In this example, replace `'data.json'` with the path to your JSON file. The `json.load()` function reads the JSON file and returns its contents as a Python dictionary. You can then work with this dictionary in your Python code.\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful coding assistant specializing in {language}.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Create a chain: prompt -> llm\n",
    "chain = prompt | llm  # The | operator chains components\n",
    "\n",
    "# Use the chain\n",
    "response = chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"question\": \"How do I read a JSON file?\"\n",
    "})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace90620",
   "metadata": {},
   "source": [
    "### Adding Output Parsers\n",
    "\n",
    "Output parsers help you get structured data from LLM responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef16781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code:\n",
      "import json\n",
      "\n",
      "# Open the JSON file\n",
      "with open('data.json', 'r') as file:\n",
      "    data = json.load(file)\n",
      "\n",
      "# Print the contents of the JSON file\n",
      "print(data)\n",
      "\n",
      "Explanation: The code snippet demonstrates how to read a JSON file in Python using the 'json' module. It opens a JSON file named 'data.json', reads its contents, and then prints the data stored in the file. Make sure to replace 'data.json' with the actual file path.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define output structure (like TypeScript interfaces!)\n",
    "class CodeSuggestion(BaseModel):\n",
    "    code: str = Field(description=\"The code snippet\")\n",
    "    explanation: str = Field(description=\"Brief explanation\")\n",
    "    language: str = Field(description=\"Programming language\")\n",
    "\n",
    "# Create parser\n",
    "parser = PydanticOutputParser(pydantic_object=CodeSuggestion)\n",
    "\n",
    "# Update prompt to include format instructions\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a coding assistant. {format_instructions}\"),\n",
    "    (\"human\", \"Show me how to {task} in {language}\")\n",
    "])\n",
    "\n",
    "# Create chain: prompt -> llm -> parser\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# Use it\n",
    "result = chain.invoke({\n",
    "    \"task\": \"read a JSON file\",\n",
    "    \"language\": \"Python\",\n",
    "    \"format_instructions\": parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(f\"Code:\\n{result.code}\\n\")\n",
    "print(f\"Explanation: {result.explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88a23f",
   "metadata": {},
   "source": [
    "## Part 4: Building a Simple Chatbot\n",
    "\n",
    "Let's create an interactive chatbot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! A vector database is like a giant file cabinet where information is stored in a way that makes it easy to find and use. Instead of just storing data like words or numbers, a vector database also remembers the relationships between different pieces of information. This helps us quickly search for and retrieve the specific information we need, kind of like having a very organized and efficient library for data.\n"
     ]
    }
   ],
   "source": [
    "def simple_chatbot(user_input: str, system_prompt: str = \"You are a helpful assistant.\") -> str:\n",
    "    \"\"\"\n",
    "    Simple chatbot function.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's question\n",
    "        system_prompt: System instructions for the bot\n",
    "    \n",
    "    Returns:\n",
    "        The bot's response\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"input\": user_input})\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "# Test it\n",
    "response = simple_chatbot(\n",
    "    \"Explain what a vector database is in simple terms.\",\n",
    "    system_prompt=\"You are a teacher who explains complex topics simply.\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c0b91",
   "metadata": {},
   "source": [
    "## Part 5: Observability with LangSmith\n",
    "\n",
    "LangSmith helps you debug and monitor your chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have LangSmith configured, your chains are automatically traced!\n",
    "# Let's make a few calls to see them in LangSmith\n",
    "\n",
    "test_questions = [\n",
    "    \"What is the difference between a list and a tuple in Python?\",\n",
    "    \"Explain async/await in simple terms.\",\n",
    "    \"What are the benefits of using type hints?\"\n",
    "]\n",
    "\n",
    "print(\"Running test queries...\\n\")\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"Q{i}: {question}\")\n",
    "    response = simple_chatbot(question)\n",
    "    print(f\"A{i}: {response[:100]}...\\n\")\n",
    "\n",
    "print(\"‚úÖ Check your LangSmith dashboard to see traces!\")\n",
    "print(\"   https://smith.langchain.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19105331",
   "metadata": {},
   "source": [
    "## üéØ Day 1 Exercises\n",
    "\n",
    "Try these exercises to practice what you learned:\n",
    "\n",
    "### Exercise 1: Custom Chatbot\n",
    "Create a chatbot that acts as a code reviewer. It should:\n",
    "- Accept code snippets\n",
    "- Return suggestions for improvement\n",
    "- Rate the code quality (1-10)\n",
    "\n",
    "### Exercise 2: Structured Output\n",
    "Create a chain that extracts key information from a meeting transcript:\n",
    "- Attendees\n",
    "- Action items\n",
    "- Decisions made\n",
    "Use Pydantic models for the output structure.\n",
    "\n",
    "### Exercise 3: Model Comparison\n",
    "Try the same prompt with different models on OpenRouter:\n",
    "- `openai/gpt-3.5-turbo`\n",
    "- `anthropic/claude-2`\n",
    "- `meta-llama/llama-2-70b-chat`\n",
    "\n",
    "Compare the responses and trace them in LangSmith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79325d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Hint: Create a CodeReview Pydantic model with fields for suggestions and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420efaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Hint: Define a MeetingNotes model with List[str] for attendees and action_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c977b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "# Hint: Create a list of model names and loop through them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a263fea2",
   "metadata": {},
   "source": [
    "## üìù Day 1 Summary\n",
    "\n",
    "**What you learned:**\n",
    "- ‚úÖ Python essentials (compared to JavaScript)\n",
    "- ‚úÖ LangChain basic concepts: LLMs, Prompts, Chains\n",
    "- ‚úÖ Prompt templates with variables\n",
    "- ‚úÖ Output parsers with Pydantic\n",
    "- ‚úÖ LangSmith observability setup\n",
    "- ‚úÖ Built your first chatbot\n",
    "\n",
    "**Key concepts:**\n",
    "- **Chain**: Components connected with `|` operator (prompt | llm | parser)\n",
    "- **Invoke**: Method to run chains with input\n",
    "- **Pydantic Models**: Type-safe data structures (like TypeScript interfaces)\n",
    "- **Tracing**: LangSmith automatically tracks all chain executions\n",
    "\n",
    "**Next up (Day 2):**\n",
    "- Different chain types (Sequential, Router)\n",
    "- Conversation memory\n",
    "- Context management\n",
    "- Building a stateful chatbot\n",
    "\n",
    "**Resources:**\n",
    "- [LangChain Python Docs](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [OpenRouter Models](https://openrouter.ai/models)\n",
    "- [Pydantic Tutorial](https://docs.pydantic.dev/latest/)\n",
    "\n",
    "Great job! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
